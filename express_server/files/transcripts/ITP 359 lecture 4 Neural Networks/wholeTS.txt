output is the same again and so no information becomes really important now for the for the networks here so you're basically have as your approximator now I ride w dot data right you're basically say Okay I want my approximator to look like this and that is the basic choice of your neck right so each node uses a linear combination of the features of feature vectors and the associated weight that is the basic idea of your life right so the approximator looks like this and each nose does that right so you basically have your M features remember the nomenclature right and for each data instance that's how youthat's that's your approximator right so you have M weights in this in this case here and W is then the waiter and you also introduce a bias so basically your trying to introduce them another constant with another weight the idea behind the biases then it it makes training of the network actually way way faster because you have a way to offset right so you basically can train or can set this bias to 100 or 1,000 or whatever you want and therefore offset the value immediately as opposed to it's cruciatingly slow adjusting your weights up right so that you get that so over the bias you can immediately scale up and down so that's why the bias was invented and it has proven to be extremely important and so anyways that goes into the into the note and you can write this very compact form using you know the dot product here this will then become the Matrix the matrix product okay and in a more and then the output of the of the new one right is basically you determine through an activation right so you say the output of the whole of the neuron you just take what we just did so that linear combination with the bias and you run that through a step function right so in the later will use a sigmoid function for that or or whatever in this caseand that's your gets you out right and then yeah training this person means finding these maid parameters okay so that's that's pretty cool and you can already see this is perfect for the binary classes no problem the problem is actually that the step function is not a nice fun right so it's not different okay so how do we train this thing so it's only the person so the output is is binary right and the question is what is the Lost function actually for a situation so in we already talked about this this binary case if if the target is between minuses either -101 and then we we solve this problem here of minimizing this function now I'll call it B by the way just to not confused but it's the same as we had before so we basically minimize you know this song heregive me just say Okay this approximator that we talked about before we now replace that with the step function of the linear combination that we just as well so fill that in right and then this is actually the same thing as riding it like this right so we just take the outputs here which are either a zero or one minus that step that output right step function not the linear combination and then minimize this expression here or find the parameters to minimize that expression so think about this is actually the same thing this let's say this is 0 our Target is zero and the step function contributes a one or a minus one doesn't matterconfused the minus one this expression is plus one that you contributes a plus one this expression is minus one but we have to take the absolute value so this will be a one so that's bad it's so that contributes to the sum it means we missed classified let's say this is zero it doesn't contribute let's say this is one and this is 0 again it's contribute and so we basically with this minimization here we minimize the misclassification off our off our little perceptron there which is the exact same thing as riding it like thisand then how we would train it okay we start with the weights being zero or any random number but it should be small so it's it's very important to not have them be too big it might be a big problem for training so usually zero is a good idea and I did step two we for each of the data points right and we perform the following steps right so we calculate this out as we discuss all the dress up front so the linear combination that happens inside the note and then a reply is that function right supposed to be here and then we update the weights in this fashion here right so this is the approximation right and then we just take the distance between the approximation and the actual value right and then multiply that with the learning rateand then multiply that with the actual x value in the new weight is then just the old way plus that guy and you might remember this equation right so the it's basically the same equation that we have for linear for that but it's ready ready to send right or we get something very similar with the one right the person looks a little different but it's at the other day the same the same idea right so we update the weights and each step and for each data point right according to buy by calculating the systems here and multiplying that with the lowering right and then we repeat that and certain number of times right until you know this error here that's all I lost function that we just defined until that is very very small or after we stop after a certain numberwe don't have to ingredient descent you might recall we needed to take the derivatives right because we needed to identify the slope and go down the slope in the loss function we don't have to do that here right so this algorithm already gives you the optimal setup programs and then the perceptron basically can work very very well on a simple data sets we use that little demo room so you know with clusters like this it works very well with classification it has it's troubles with circular data like this or even the famous spiral but even other models are problemsyeah but the person does a really good job at anything where you can easily draw a decision bound right so leave me alone it's called linearly classifiable Data it doesn't really good job right so anything where it's easy to to draw Lydia online between the clusters of the different classes it's going to do a great job if it's not possible to draw a straight line so if it you have to draw a circle or even worse in the spiral like the broad spiral it won't work well and that is you know one of the things obviously that makes no Networks attractive as classifiers because they're renewal Nets right so the perceptron we use a step back as an activation function for a newer networks will use a sigmoid function or hyperbolic or something so a nonlinear function that nonlinearity will allow us to learn non-linear relationships something the perceptron can't do because it just use that step functions but then your networks are non-linear approximators right so that's why it will be it will be able to approximate also these nonlinear problems perioddemo not going to over that too much for I want to actually now discuss the new on Netflix so remember no we we have for a dual network we now have a variety or of layers and no fries or busy take it first uptron and just have it as many of those and the step function that we use and now is replaced with either a sigmoid function or the real or for this the logistics function here but we can also use in Hamburg tensions very popular and the other day that non-linearity is really what this is all about and then this is how you construct your multilateral New Orleans so as I said this is all about indexes so is this looks like oh my God because I know where I can understand this but it's actually quite straightforward if you pay very close attention to index is my favorite slide of ultimately and it's all so you have your inputs and then you have your hidden layers right and you might have many of those right in this case we haveand each of those key layers they have a number of notes right in this case I call them Lambda right Lambda one for the first layer and all the way to Lambda cap groups right and how are you now Define the network is you basically started the end right so you start down here and you say okay the output is activation function I don't want to call it stick mom take him away because it all so we have a balance and whatever so activation function of the output weights times the out of the final layer right inspector right of the output so this is exactly the same equation that we had for the same linear combination that we did with the perceptron just a little more complex because this is a matrix and isn't a matrix but no problem at the end it works the same way right so that's how awesome and then you define and then you look into HP what is that well HP is defined by the layer before right because all these nodes are connected to each other and they feed four right that means this knows here gets fed by all the nose from the previous layer right and this note as well right and this note gets fed by all the notes in the layer beforeadded activation box got it yeah really hyperbolic tangent or sigmoid or something like that so I can non-linear activation is the no so I I pick out a note here it depends on the nodes off the previous layer and all the notes of the previous right that is why this is what's called a fully connected feet forward now meaning that all the nodes always feed forward into into the nodes of the next light right so don't get confused by the whole thing this node in in layer k depends on the notes of the layer from before right that's the only thing that really matters right and then those weights are then you know attached to each of those each of those notes right and then you go back all the way to the first night and that first layer that now depends on the input vectorwork your way back so the output depends non-linearly on the last layer the last layer depends on the layer before and any layer any node in the network depends on all the notes in the layer before all the way to the first layer and that depends now on the input so you can actually write it like this it's really cool it's a it's a it's a recursive way of writing in your network right so you start here first layer depends on the input that is then fed into layer 2 that is fed into a layer 3 and so on and you basically peel like go like outwards in the audience right until you reach layer P minus one that's I made it blue and that is then fed into a layer pee which is the purple stuff and dad is then finally created a Fed into the final linear activation functions created so and neural network is basically just an onion right that starts with the with the output and then you go back all the way to the input and then you you have the input now you can calculate it and then you go back to actually calculate you right so it's very very elegant ingot the recursive way of defining it and yeah the universal approximation theorem then this is this guy's important cuz I thank God 1989 and Truth the following the feet forward with a single hidden layer containing a final number of finite number of neurons so one layer find out number of neurons 10 20 whatever and approximate any continuous function on compact subset subsets of Orange right doesn't matter what compact subsets are meaning come so you have a subset and it's compact just means that you don't have you include you include the boundary we do not have to put a lot of constraints on the nature of the activationthe activation function just has to be nominated and that in a different way a mathematicians will know what this means is that neural networks has a function class are dense in the orange right and that's that's like super excited wow because you could basically approximately that's spurred a lot of renewed interest in your headphones when they when that was cool it's not hard to prove it's actually interesting the to phrase it sometimes takes longer than food it right it's because there is some constraints and some things here and there but at the other day it's it's quite it's quite simple yeah and then we talked about multi-class neural networks right so what we discussed here was always one output right or was it one output now you can have multiple classes no problema little all little Iris little Irish flowers there right and multiple classes then work in the way and that we basically have a raw output of the network right usually call them debt right and then we apply and sigmoid function to actually get to and sigma is only always between 0 and 1 right so we basically get some type of probability for a class right so let's say you get the raw output you apply a sigmoid it's going to map it to between 0 and 1 and that's going to be some type of probability for each of the three classes yeah the problem here is that's this doesn't add up to one right and you would actually say whatever you classifying belongs to class 1 and class 3 hereso this is called when you apply only is Sigma function so at 3 point function at the end and this is a in fact a multi-class classification and if you we also discussed quite extensively the softmax variant effect right so were you apply a soft packs function in the final layer so here in the final layer we only apply the sigmoid function right which does not why the probabilities don't add up to one and it is not possible to be sure that you end up with one class you could class you could actually classify this several classes as well it's called multi-class and you might want that right you might want to be able to tell it's actually what a lot of networks do all right you can say highest probabilities this class but then this class is not far behind with the softmax you blow these things out of proportion right and you basically map one class to almost one and the other classes you suppress So Soft exaggerates the differences in the probability and it Maps it to always add up to one that means you have a absolutely exclusive belonging or mapping to a class and we might remember so soft Max looks like this soyou're basically through the denominator here you make sure that you that you map that that your values add up to one right which is something that you truly want in a in a in a binary class es where you want to have one to end up with one class as the classification the probability but you might want a comparable and probability which one between the different outcomes right so let's say you're a classifying between dog and cat you want one answer either a dog or a cat but what if you were classifyingimage or certain things an image and you want to have all the different possibilities of what it could be right and we actually saw that in a different example more towards the end of the semester where we we saw probabilities ranked right and there you might want something like this right where you actually can rank the different classes and they're comparable right because here the distance between those is in fact not very large in a soft Max you exaggerate the distances right and then it does not really comparable so if you really want to see like a ranking of the different possible outcomes then you would do something like thisbut here you go that our proportion right I mean softmax looks like this right so you you basically you penalize small small values right and you exaggerate large values of problems with something very discrimental answer sample right so classifier oh yeah and then classification loss right for multi-class classes so we already discussed the negative log likelihood here right that's basically comes from this hole and then the softmax doesn't give anything new but what's important is the cross entity sorry I talked about that already so basically now we have K classesand the cross entropy loss is now looks very similar to the negative log likelihood and it is in fact negative log likelihood is cross entropies for the binary case right where you only have two classes how cross-ended to be lost looks like and that's what we use all the time in our models you can see it looks very similar it just has one term in the sum but think about it and you might have to do that at home if you now only have two classes this becomes exactly that equation here see this plus here these are now the two classes right so k equals 2 then this becomes two terms right from the sum here and then you have the same same equation as the negative log right so that's the same the sameand again it comes from the from you know this this whole process of saying okay we're kind of like us to take the logarithm and then apply or maximize a lot the likelihood function and that's you know it means minimized negative block likelihood Etc that's how you do it arrive at the Crossing and we always use and we use as a final activation function the softmax here you know gives us out for probabilities that are all that add up to one we have a very clear winner in this and then you know minimize stuffhere to find the parameters just a word the softmax is only applied in the final layer the other layers have any other activation parts and remember that and our code usually softmax is only for the final layer to map that to probabilities and then this is from my seat for my pieces by train the multim player Network there and it's actually very old the How to Train this thing is ready to send so we we discuss some of that already so you know you have a loss function for regression you know we use this mean square error right and classification we have crossed cross entropy and thenis in a similar to or it's actually the same thing as the perceptron right just that depression has you know the derivatives result in an easier easier equation there for in our case we have to change the derivatives here in more General case of the loss function to update the weights derivative of the loss function are that is the big problem why these things take so long to train on your computer right calculating derivatives is is computationally expensive right and we have to take derivatives here towards all the way so there's a lot of derivatives to take and you have to do this for all database that's by the way why we use sarcastic right into something SGD that only samples and small number of data pointsand you basically stop when you reach the plateau right so when your derivative becomes 0 so you're basically at this point you now oscillate around this and song actually next time I'll show you some parameters to avoid that so there's a lot of problems with this you can you might not find the right anymore you might be stuck in a minimum that's going back to my stuff here you might be stuck in a small minute and not in the basement how do you know that big disadvantage of some afraid to send how you do that is there's somebody called boosting for example where you try to jump you just boost to some other place and then see what happens if you find a different way and sarcastic boosting it's called it there's another problem about oscillation so when this become that needs to become very small you oscillate round of the minimum there and that can be suppressed using momentum and I'll show you it's just a parameter that you add in the compiler so anyways it in principle this this works right so you try to find them minimum by adjusting and you know the weights using the negative of the negative slope here right going down towards the new moon but again it is very difficult or impossible to find the globalness you might be stuck in a smaller and many many smart people have put thought into how can you find the right or the best thing but in our case all the models were trained use their pain to send or sarcastic rate to send or Adam right you might have seen Adam is just just means that the learning rate is justso and then back propagation so I went to class everybody the derivatives in fact is derivatives here they are calculated using chain rule right so when you take a derivative off the of the Lost function towards a certain weight you you're basically you would you travel back to your network like we did before all the way to your input limit right that's called back propagation because the derivatives derivative of loss function in a certain layer depends on the layer before and it depends on labor before is that right it comes from the chain rule