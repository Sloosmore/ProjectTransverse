you have to reserve space so close I was doing some testing right before I got here although it through one error at me but it's not 8:00 I got to stop like turn off oh and the arrow is gone because I'm talking so much I thought I was this time I actually have a reason to sit at the front although I want to be able to pick up the audio test it but right now I just need it working like just working yeah I just need working and then I can I can optimize that the other thing is it's kind of weird that when it's active I'm putting some use effects in there but it's only refreshing when I actually like physically reclick on the thing so I'm not to figure out what that is like how to re-render and it's using like use location to pull basically from yeah use location to hook to pull it from a from the link so maybe that has to do with it I need to figure out like how to force it to rerender but I don't think that'll be too big of a problem no but that's what I've been doing that and it hasn't been rendering which is weird which rooms are actually going to be the seller's rooms but it's it's one of them the phone 's unfortunatelyany other questions you guys have so far I'm admin items or anything like that so I uploaded a new version of the syllabus I made it slight adjustments and you are too expired adjustments so one is I move the exam into the Sprint the week before spring break so before on the syllabus I don't know February 29th and now I moved it to the Tuesday of that week before spring break I think tomorrow not very surprising and the other little change I made I made a change actually in the way I'm going to do the first couple lectures soLucy's it's not a big change but I first want to do the forecasting so I'm sorry that next week so today we'll do a little review session so today will only be review of last semester because I want you to be on the same terms as I am on in terms of and then next time I wanted to forecasting something that we did a little bit but I want to do forecasting in a variety of ways some of it's new and then next week I want to do a Markov chains and a naive Bayes outboard which is something that we didn't do last semester but these are important statistical methods I'll introduce those who has done that who has ever done a hidden MarketI saw that a lot of algorithmic Traders people in finance had backgrounds in them sequential data in fact that is used for trading for example but it's also used for audio processes and so I'll actually then next week so we say I think do a walk through a house speech like audio to to text recognition works right so how do well how do you transcribe things right and you can do the variety of things you can use it all networks but you can also ask the classic technique and somehow feel like I don't want to leave this course you're always with the impression and everything in life right I mean there's a lot of statistical models out there that are extremely effective right so I want to show how audio processing Works using hidden Markov models and I think that's kind of cool the my my background is a lot of Statistics so I always approach things from that and then after that will go into Auto encode or something an auto and quarters are really really important and then after that variational model and variational auto and cores are going to be the first deep generational models that generation model sorry that we're going to use so hidden Market models are already a generated modelgenerated AI that you guys are thinking of the generator AI is in fact although we're going to start with variation oil and odors in those types of models so we're going to get to them already and about 2 weeks from now and then Yahoo any questions so far so the first homework I'm going to do on four casting which will do well this week I'm still thinking if I want to do a homework then next week so we might actually have a little bit of a one week off with homeworks I'll end up with about eight or nine homework during this semester right but we might already have the first one come out on Thursday it depends on how quickly I get through the forecasting because I don't want to rush anything we have a lot of time there's no need to rush it right so the homework will be either s*** on Thursday or on Monday Tuesday all right dive into soup machinethe you'll see I I approach this whole topic as an approximation problem right so you have a problem with the Target and you trying to approximate or you're trying to find a function that approximates your problem right so you know that works and so on is nothing but an approximation and there's a variety of way to do that statistical methods or you know numerical methods and so on so I'm going to go over that in a little bit and then linear regression logistic regression and neural networks you've heard about them not semester and to go through this and probably going to be fast but feel free to stop me try to not be too fast but I I know you guys have heard some office I recap is always important I'll do Recaps before the exams as well I think it's always good to hold still for a second and remember okay so we talked about the AI approaches last semester and we basically spend most of our time with clustering techniques so unsupervised learning techniques for example the K means algorithmregression classification but an also of course ordered neural network right and for classification you know that was a variety of things you did of course neural networks we use for classification of those pattern an algorithm to K&N algorithm the canoest neighbor algorithm for classification and recommendation for a movie it's part of it uses right to to give you that recommendation so it's real these are algorithms that are used we also did a pretty brief intro last semester into Association analysis and we use pcas or principal component analysis in in some points but we didn't spend lot of time on that let alone on search problems right I'm actually a huge fan of search problems I hope I can convince ITP to do a whole class on search I mean this is cool stuff traveling salesman I I remember actually a real story in high schoolI was traveling salesman problems in high school I I participated in the research competition what we tried at the time over the 1997 or something that dad's was really really cool I still fondant so I have a little bit of a knack for search problems but we don't do that a lot week but anyways so we circled a lot around the question from a statistical standpoint or from a machine learning standpoint? and then we'll suspend some time on clustering supervised learning so you all know is the main differentiator is Target very good right so you have a data set and you have label data right that means you basically tell the machine okay these are theyeah you basically tell them the outcome of the certain data point that you're feeding them you know is a good bad as the cat or a dog or whatever and we use several different classification I'm not sure how far you got it to support Vector machines I didn't do much of that they are obviously very very popular especially in English and there's a number of others I will in this class now introduce a naive phase and also some other as we discussed for a classification something that we skipped over last semester but at the end I'm I'm sure you call a lotokay nomenclature right so I will always use the same noise myself and I wanted to introduce it here and I have the slide then I'll have them in several other locations through everything so we always have you know we have all features and we have our Target right the the features we always have in my own pleasure M number of features an N number of targets and I write the instance of the data set right so basically the role in the data set with the cap with the super scripts in in parenths other people do that differently right but we always have the index problem with your networks right so that works our machine learning in general you always have the problem that you have a ton of indices indexes and you don't know where so I always write it in the way that lower script I write the feature number right so one to m and upper script in brackets I write thethen that keeps it as clean as possible but you'll see that at the end of the day it's still there's a lot of working through indexes right so but I will always come back to this moment I've never okay and so regression we you know the basic problem we're trying to solve is 40 years so we're trying to find it approximately that depends on the feature vector right so the pictures and a certain number of parameters I usually call them data so when I when I talked about General parameters called them say yeah when we talked about and your network I usually switch to Dublin the weights so Theta General parameters but approximation problem always means that we have a Target and then we're trying to find function that approximates at Target up to a certain errorobviously will minimizing this error and so pretty pretty straightforward you have is actually a this is a complex problem right so I mean it sounds simple like okay let's find a function that does this but there is there's Decades of theory that went into how to do that what type of function classes to this fast and how to etc etc we have seen that we will networks as a specific function class are especially good at this and there is the as a theorem Universal approximation theorem I think I have it here on the slide that tells us thator function class that can for any smooth function minimize this error too zero right or just there so that is quite powerful that's why they have gotten so much attention right because they are a universal approximator so they can basically approximate any smooth function average rarely well so that's quite cool in an important number that we that we always look at is the dimension of the exactly listening to me yeah no it's doing really well yeah and so you see our function here basically projects from theDimension M into a new space right Dimension L right and that's the dimension of the problem we you often have L equals one right but by no means this has to be done we will not spend too much time on this problem but this isn't a problem right the dimension is very high of your problem then you know that will be a computational problem period curse of dimensionality and so there's a big problem all right so regression so choosing this F here so our approximator that is called modeling right so choosing it Mark up model that's one model choosing a neural network it's another model right so it's a very very fundamental decision how do I want to approximate my problemmodeling and you already make a mistake when you model because you might get it wrong right an example is very simple one you have a blue data points you decide I think it's a straight line so I'm fitting a straight line through that that is a choice of a model you choose a straight line as your model and then you know you approximate it it'll approximate your data in some fashion but you already made a mistake with that model right you could have taken you could have chosen you know different type of function you could have taken there or whatever and would have figured much right but maybe it would have overfitted to you and so choosing the model is a really really difficult taskwe choose the network architecture and can some of you tell me how do we choose how many nodes how many layers do we want how many Dropout layers like how do we change that how do we choose the number of nodes that say and then you know and number one players cross validation it's a it's a big problem with that machine learning is obviously if you're in if your model is too complex you will overfit and in the 2000s when I roll my pieces on it it was actually dominating from that you really have no idea how complex do you have to choose your model and is very fast to overfit today has gotten better theso when you look at the python packages subtract accuracy involves and all these things you you will have a much better sense for how are your models doing and if it's overfitting or not but it's very easy to construct a problem where you vastly overfit so modeling choosing the right number of parameters and so on is an architecture is a is a real big problem you know you you can just feed in more data and hope the models get better if the architecture if it's for example if you don't get the complex ity with Chachi PT and those GPT models that was actually one of the things why people got a little surprise because they had they they showed almost like an exponential increase of actorswhich is something that they that you wouldn't have expected and so they don't seem to have a big problem with overfit those models okay so linear regression just to come back to this will be choosing a model that looks like this right so you have and parameters and then you construct the function like this so one next one plus day I am XM right that would be a linear regression if you only do if you do m equals 1 so you only do do the first part here that is just a straight line right logistic regression we saw last semester you choose a model that looks like thisthe easiest one you would choose a model that looks like this so nothing magical about this right this is just a certain type of approximator you're choosing to model your day really nothing Magic actually it looks less complicated than even though but yeah we all saw you know how powerfully all right and then yeah you use different models for different situations but obviously those moms here are extremely fast in training them and all that dual networks can be used for any continuous function so that is really a very very cheap and then what are the key things that we talked about a lot was the last function right so how do you determine these these parameters and how would we determine those as well we measure the error that the model is making right I mean in the simple picture here is just the distance between points and data points and then minimize that distance and wein this case we just Define as the euclidean distance so you just say okay the actual physical distance so we're saying right on distance at this point here from from the straight line distance is not always easy to Define I mean in a case like this easy to Define but how would you for example Define the distance between two customers I watch a movie you watch a movie how do you determine the distance between me and you right or between the movies right so distance is not straightforward and in fact one of the most important pieces because the distance is or whatever we use for a measure of that is going to be the function that were minimizing on the training the network could discerns very straightforward nicely you measure the distance between the function and Target which is the error right remember that's equation that I had in the Box this is just a error Epsilon that I haveit's harder classification problems you can measure distance as well how do you measure distance between cat in the mouse and you try to classify those images so in classification problems you need to argue through probability and so we'll get to that now but for a regression problems like this very very straightforward I'll be fine the the whole topic of distance has it could do a whole separate lecture on that right it's it's called measured Theory it's it's a it's a very fundamental math class were you concern yourself exactly with this question of like how do you measure distances between sets and and all that and it's the base is actually off integral