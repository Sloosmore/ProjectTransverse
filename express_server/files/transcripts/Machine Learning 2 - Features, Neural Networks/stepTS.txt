2024-01-17T01:35:15.102Z>
- Due tomorrow at 11:00 p.m.
- Deadline is at 11:00 p.m., not 11:59 p.m.
- Encouragement to complete a test submission early to avoid any last-minute technical issues 
- No penalty for submitting something before the deadline and checking for issues
- Students are responsible for any technical issues and are encouraged to test submission early for peace of mind<2024-01-17T01:38:03.867Z> and in symbols this is the training loss which depends on a particular weight Vector is the average over all examples in a trading set of the loss of that particular example with respect to the way Vector W okay and we want to find the W that minimizes the training loss so we want to find the single W that make sure it's on average all the examples have low loss okay so looking at the loss functions now this is where it depends on what we're trying to do if we're doing regression then the permanent thing to look at is the residual which remember is the models prediction minus the true label so this is kind of how much we overshoot and the loss is going to be zero if the residual is zero and it increases either quadratically for the square loss or linearly for the absolute deviation depending on how much we want to penalize large deviations for classification or binary classification more specifically the permanent quantity look at is the margin which is the score times of the label Y which remember is plus one or minus one so the margin is a single number that captures how correct we are so large margin is good in that case we obtain either a 0 or near zero loss and margin lessons 0 means that we're making a mistake so the zero on Lost captures that we're making a mistake of the lost one but the hinge loss and religious question like I know