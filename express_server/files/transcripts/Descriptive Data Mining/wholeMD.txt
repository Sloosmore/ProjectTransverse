# Descriptive Data Mining 

## Data Mining
<2024-01-17T17:08:45.764Z> 
- Data mining is the process of analyzing large sets of data to discover patterns, trends, and relationships.
- With the advancement of technology, we now have the capability to extract valuable insights from the vast amount of data that is being generated.

## Data Mining
2024-01-17T17:11:47.830Z
- Data mining is the process of analyzing large sets of data to discover patterns, trends, and relationships.
- It involves extracting useful information from a large amount of data, often using automated methods or algorithms.
- Companies use data mining to gain insights into customer behavior, market trends, and other business-related information.

## Interest Rate Period
2024-01-17T17:11:47.830Z

- Interest rate period is the duration for which a specific interest rate is applicable for a financial product.
- In AI, data is highly valuable for companies to derive insights and make informed decisions. 
- The process of mining and analyzing data allows companies to extract actionable information and drive value. 

## Algorithm and Qualitative Assessments
2024-01-17T17:13:02.993Z
- Algorithm: A set of rules or processes to be followed in calculations or problem-solving operations, especially by a computer.
- Qualitative assessments: Evaluations that are based on qualities or characteristics rather than on quantity or numerical data.
- Consider the use of qualitative assessments in decision-making processes.
- Discuss the potential impact of qualitative assessments on business decisions.

## Cluster Analysis and Similarity
2024-01-17T17:14:11.304Z
- **Cluster Analysis**: A method of grouping objects based on the similarity of their attributes or characteristics.
- Data preparation is underway.
- Two ways of dealing with daily money have been mentioned.
- Mention of clustering of similarity for computer reports and association rules.

## Computer Grouping and Data Analysis
- The process of grouping data for significance and analysis.
- Utilizing computer algorithms to group similar data together for analysis and decision-making.
- Methods for determining similarity and measuring distance between data points.

## Grouping data and measuring similarity 
- Date-time: 2024-01-17T17:15:36.708Z
- The data is grouped to find significance and aid in decision-making processes.
- The computer can identify similarities between data using numerical comparisons.
- Similarity can be measured by comparing numbers, such as age and income, using methods like z-scores and standard deviation.

## Scale and Range of Values
2024-01-17T17:17:59.707Z
- Range of values: The difference between the minimum and maximum values within a dataset.
- Age versus income scale: Income is in the tens of millions while age has a lesser range.
- Z-scores: Standardized scores that measure the distance of a data point from the mean in terms of standard deviations.
- Using z-scores to fix scale issue and bring values to the same scale for comparison.

## Z-Scores Explained
2024-01-17T17:19:44.396Z
- Z-Score: A measurement of a value's relationship to the mean of a group of values, measured in terms of standard deviations. It indicates how many standard deviations a data point is from the mean.
- Discussion of using Z-scores to analyze income data and how it can affect the distance equation in analysis.

## Analysis of Distance and Z-scores
- 2024-01-17T17:20:55.708Z
- The computation of distance between data points is essential in analysis
- Z scores dominate the distance equation, which can skew the analysis
- Z scores transform data values to represent their distance from the mean

## Standard Deviation and Z-Score
2024-01-17T17:22:09.712Z
- **Standard deviation**: A measure of the amount of variation or dispersion of a set of values. It illustrates how much individual data points differ from the mean.
- **Z-Score**: A statistical measurement that describes a value's relationship to the mean of a group of values and quantifies how many standard deviations above or below the mean a data point is.
- The discussion pertains to using Z-score values to determine the distance between data points and how it relates to clustering analysis.

## Floating Point Numbers and Categorical Data
2024-01-17T17:23:25.406Z
- **Floating point numbers** are numbers that contain a decimal point. They can represent a wide range of values.
- **Categorical data** refers to data that represents categories or groups, such as colors or types of fruit.

## K-means Clustering
2024-01-17T17:24:45.638Z
- **K-means**: A popular unsupervised machine learning algorithm used for clustering data points into a pre-defined number of clusters.
- Comparing data points to find clusters for poster creation, based on the nearest neighbors.
- Exploring the process of creating clustered groups on the ground.

## K Means Clustering
2024-01-17T17:25:41.736Z
- K Means Clustering: a type of unsupervised learning algorithm used to group similar data points into a fixed number (k) of clusters.
- The algorithm iteratively assigns each data point to the nearest of k centroids and then recalculates the centroids based on the mean of the assigned data points.
- Involves choosing the number of clusters, initializing centroids, assigning data points to the nearest centroid, and updating centroids.

## Hierarchical Clustering
2024-01-17T17:26:51.716Z
- **Hierarchical clustering**: A method of cluster analysis which seeks to build a hierarchy of clusters. 
- Hierarchical clustering can be advantageous when working with small datasets, as it enables the formation of clusters from individual observations, but it may not be suitable for large datasets as it can become computationally intensive.
- Outliers can greatly impact the output of hierarchical clustering. The presence of outliers can affect the distance measurements and ultimately influence the clustering process.

## Hierarchical Clustering and Data Preprocessing
2024-01-17T17:28:04.717Z
- Hierarchical clustering: A method of cluster analysis that builds a hierarchy of clusters by either merging or splitting them successively.
- Outliers removal: The process of eliminating data points that significantly differ from the rest of the data to improve analysis accuracy.
- Handling large datasets: Hierarchical clustering may not be efficient for datasets with thousands or millions of data points.

## Data Mining and Clustering Analysis
- Data mining is the process of analyzing large data sets to identify patterns and relationships.
- Cluster analysis is a technique used to group similar data points together based on certain characteristics.

## Data Mining and Cluster Analysis
2024-01-17T17:31:28.691Z
- Data mining is the process of analyzing large sets of data to discover patterns or relationships.
- Cluster analysis is a technique used to group similar items or data points together.

## Converting Language to Numbers
2024-01-17T17:40:33.694Z
- **Unstructured Data**: Data that isn't organized in a pre-defined manner and doesn't have a specific data model. 
- Computer processing text requires converting it into structured numerical data for analysis.
- The process involves identifying important information from the unstructured data to create a set of numbers for analysis.

## Structuring Text Data for Analysis
2024-01-17T17:44:11.693Z
- We need to structure the text data to be something that can be plugged into SPSS, Rosen Collins, or equivalent tools.
- We can create a term document matrix where important words are picked out and presented to the computer as a set of words.
- A term document matrix allows us to pick out important words and provide this information to the computer, enabling analysis.

## Structuring the Data for Analysis
2024-01-17T17:44:11.693Z
- Term Document Matrix: A way to represent the words in a document as rows and the documents themselves as columns. 
- SPSS and Rosen Collins: Refers to statistical analysis software used for processing survey data.
- The speaker is discussing the process of creating a term document matrix to analyze survey responses.

## Clustering of Textual Data
2024-01-17T17:45:25.390Z 
- The process involves analyzing the frequency of words in a set of data to identify patterns and similarities.
- Tokenization is the process of breaking text into individual words or tokens for analysis and is a crucial step in clustering textual data. 

## Tokenization and Text Preprocessing
2024-01-17T17:46:50.004Z
- **Tokenization**: Process of breaking text into individual words or tokens for analysis.
- Remove non-word characters and punctuation marks from text data.
- Convert all words to lowercase to ensure consistent analysis.
- Identify and handle word endings to unify related terms.

## Identifying and Processing Words
- **Stacking**: The act of placing one item on top of another.
- **Algorithm**: A step-by-step procedure for solving a problem or accomplishing a task, often used in computer programming and artificial intelligence.

## Discussion on Natural Language Processing
2024-01-17T17:48:05.422Z
- Natural Language Processing (NLP) - a field of AI focused on enabling computers to understand, interpret, and manipulate human language.
- Importance of standardizing text - converting all text to lowercase can help in simplifying the processing of data and reduce the variations due to upper/lower case.

